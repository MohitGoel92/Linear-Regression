{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import boston_dataframe\n",
    "boston_data = boston_dataframe(description = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = boston_data[0]\n",
    "ds_desc = boston_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop('MEDV', axis = 1)\n",
    "y = ds.MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We observe no missing data\n",
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "MEDV       506 non-null float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],\n",
    "              [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 3.5, 4.5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean along the columns\n",
    "a.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean along the rows\n",
    "a.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.array(X_scaled)\n",
    "manual_transform = (X2-X2.mean(axis = 0) / X2.std(axis = 0))\n",
    "np.allclose(manual_transform, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the coefficients with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0   -0.108011\n",
      "1    0.046420\n",
      "2    0.020559\n",
      "3    2.686734\n",
      "4  -17.766611\n",
      "5    3.809865\n",
      "6    0.000692\n",
      "7   -1.475567\n",
      "8    0.306049\n",
      "9   -0.012335\n",
      "10  -0.952747\n",
      "11   0.009312\n",
      "12  -0.524758\n"
     ]
    }
   ],
   "source": [
    "# Without scaling\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "print(pd.DataFrame(lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "0  -0.928146\n",
      "1   1.081569\n",
      "2   0.140900\n",
      "3   0.681740\n",
      "4  -2.056718\n",
      "5   2.674230\n",
      "6   0.019466\n",
      "7  -3.104044\n",
      "8   2.662218\n",
      "9  -2.076782\n",
      "10 -2.060607\n",
      "11  0.849268\n",
      "12 -3.743627\n"
     ]
    }
   ],
   "source": [
    "# With scaling\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_scaled, y)\n",
    "print(pd.DataFrame(lr2.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below, we observe the most \"impactful\" features.\n",
    "\n",
    "We will use the below code to display our desired outcome:\n",
    "\n",
    "`dict(zip(df.columns.values, model.coef_))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-3.743627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DIS</td>\n",
       "      <td>-3.104044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>TAX</td>\n",
       "      <td>-2.076782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-2.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NOX</td>\n",
       "      <td>-2.056718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.928146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.019466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.681740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>0.849268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ZN</td>\n",
       "      <td>1.081569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>RAD</td>\n",
       "      <td>2.662218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>RM</td>\n",
       "      <td>2.674230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "12    LSTAT -3.743627\n",
       "7       DIS -3.104044\n",
       "9       TAX -2.076782\n",
       "10  PTRATIO -2.060607\n",
       "4       NOX -2.056718\n",
       "0      CRIM -0.928146\n",
       "6       AGE  0.019466\n",
       "2     INDUS  0.140900\n",
       "3      CHAS  0.681740\n",
       "11        B  0.849268\n",
       "1        ZN  1.081569\n",
       "8       RAD  2.662218\n",
       "5        RM  2.674230"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, lr2.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the strength of the standardised coefficients LSTAT, DIS, RAD and RM, we state that they are the 'most impactful'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures # polynomial + regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the polynomial terms to the dataset\n",
    "\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "X_pf = pf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_pf_sc = sc.fit_transform(X_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.   ,  0.   , -0.   ,  0.   , -0.   ,  0.   , -0.   , -0.   ,\n",
       "       -0.   , -0.   , -0.991,  0.   , -0.   , -0.   ,  0.   , -0.   ,\n",
       "        0.068, -0.   , -0.   , -0.   , -0.   , -0.   , -0.   , -0.   ,\n",
       "       -0.   , -0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.   ,  0.   ,\n",
       "       -0.   , -0.   , -0.   , -0.05 , -0.   , -0.   , -0.   , -0.   ,\n",
       "       -0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   , -0.   , -0.   , -0.   , -0.   , -0.   ,\n",
       "       -0.   , -0.   ,  0.   , -0.   ,  3.3  , -0.   , -0.   , -0.   ,\n",
       "       -0.   , -0.   ,  0.42 , -3.498, -0.   , -0.   , -0.   , -0.   ,\n",
       "       -0.   ,  0.   , -0.   , -0.   , -0.   , -0.146, -0.   , -0.   ,\n",
       "       -0.   , -0.   , -0.   , -0.   , -0.   , -0.   , -0.   , -0.   ,\n",
       "       -0.   , -0.   , -0.   ,  0.   , -0.   ,  0.   , -0.   , -0.   ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Lasso to the dataset\n",
    "# Note: Lasso has a default alpha value of 1\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_pf_sc, y)\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients: 26.138682362877972\n",
      "Number of coefficients not equal to 0: 23\n"
     ]
    }
   ],
   "source": [
    "# Lasso for alpha = 0.1\n",
    "\n",
    "lasso1 = Lasso(alpha = 0.1)\n",
    "lasso1.fit(X_pf_sc, y)\n",
    "print('Sum of coefficients:', abs(lasso1.coef_).sum())\n",
    "print('Number of coefficients not equal to 0:', (lasso1.coef_!=0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients: 8.472405044553074\n",
      "Number of coefficients not equal to 0: 7\n"
     ]
    }
   ],
   "source": [
    "# Lasso for alpha = 1\n",
    "\n",
    "lasso2 = Lasso(alpha = 1)\n",
    "lasso2.fit(X_pf_sc, y)\n",
    "print('Sum of coefficients:',abs(lasso2.coef_).sum())\n",
    "print('Number of coefficients not equal to 0:',(lasso2.coef_!=0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more regularisation (higher alpha) we will expect the penalty for higher weights to be greater and thus the coefficients to be pushed down. Thus a higher alpha means lower magnitude with more coefficients pushed down to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the $R^{2}$ of each model without train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366045990855128\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y, lasso1.predict(X_pf_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7207000417838496\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y, lasso2.predict(X_pf_sc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we evaluate our model on the same dataset, we may be overfitting the dataset. We will therefore analyse the performance on testing data, i.e. splitting the dataset into the training set and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pf, y, test_size = 0.3, random_state = 72018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7995486651220819\n"
     ]
    }
   ],
   "source": [
    "lasso1.fit(X_train, y_train)\n",
    "y_pred = lasso1.predict(X_test)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677935367178621\n"
     ]
    }
   ],
   "source": [
    "lasso2.fit(X_train, y_train)\n",
    "y_pred = lasso2.predict(X_test)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next steps:**\n",
    "\n",
    "- Let's do the same thing with Lasso of:\n",
    "    - `alpha` of 0.001\n",
    "    - Increase `max_iter` to 100000 to ensure convergence.\n",
    "\n",
    "- Calculate the  $R^{2}$  of the model.\n",
    "- Do the same procedure as before, but with Linear Regression.\n",
    "- Calculate the  $R^{2}$  of this model.\n",
    "- Compare the sums of the absolute values of the coefficients for both models, as well as the number of coefficients that are zero. \n",
    "\n",
    "**Analysis:** Based on these measures, which model is a \"simpler\" description of the relationship between the features and the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** From the below we observe that LASSO did a better job in explaining the additional variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients: 436.26164263064214\n",
      "Number of coefficients not equal to 0: 89\n",
      "The R2 score is: 0.8848141421367259\n"
     ]
    }
   ],
   "source": [
    "# Decreasing regularisation and ensuring convergence\n",
    "\n",
    "lasso3 = Lasso(alpha = 0.001, max_iter = 100000)\n",
    "lasso3.fit(X_train, y_train)\n",
    "y_pred = lasso3.predict(X_test)\n",
    "print('Sum of coefficients:',abs(lasso3.coef_).sum())\n",
    "print('Number of coefficients not equal to 0:',(lasso3.coef_!=0).sum())\n",
    "print('The R2 score is:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients: 1185.285825445829\n",
      "Number of coefficients not equal to 0: 104\n",
      "The R2 score is: 0.8687609133106025\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Sum of coefficients:',abs(lr.coef_).sum())\n",
    "print('Number of coefficients not equal to 0:',(lr.coef_!=0).sum())\n",
    "print('The R2 score is:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 vs. L2 Regularization\n",
    "\n",
    "As previously mentioned, `Lasso` and `Ridge` regression have the same syntax in SciKit Learn.\n",
    "\n",
    "Now we're going to compare the results from Ridge vs. Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.727,  10.354, -24.683,   5.299,  -3.13 ,  14.781,  22.301,\n",
       "       -23.483,  27.356,  -1.512,  16.949,  22.531,  11.444,   1.055,\n",
       "         0.437,  14.259,   1.83 ,  -8.737,   4.726,  -3.748,  -3.557,\n",
       "       -16.521,  -6.918,   6.064,  -1.363,   4.604,  -1.303,  -0.057,\n",
       "        -0.301, -12.828,   2.016,   1.084,  -0.655,  -1.092,   4.458,\n",
       "        -4.247,   4.156,  -1.282,   8.71 ,  -0.285,  -8.595,  11.595,\n",
       "         6.544,   1.271,   1.827,   1.007,   1.554,   5.173,  -4.685,\n",
       "         5.299,  -3.199,  -8.715,   0.983,   1.119,   0.284,  -1.683,\n",
       "        -2.884,   2.985,  -0.756,  12.297,   0.931,  -7.594,  18.292,\n",
       "       -22.124,  35.725, -21.894,  -7.789,   1.774,   4.101, -12.263,\n",
       "        -3.741,  -5.525, -16.111,  -5.706,  -4.666,  -9.884,   0.989,\n",
       "        -0.092,  17.145, -14.214,  -2.955,  -2.785,  -5.404,  11.825,\n",
       "         0.085,  -4.352,  -5.616,  -2.843,   0.826, -29.129,  49.636,\n",
       "       -21.571,  -1.263,  -8.811, -15.822,  11.975,  -1.023,   2.911,\n",
       "        -0.656,  -4.955,   2.817,  -2.463,  -2.381,   1.686])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Decreasing regularisation and ensuring convergence\n",
    "\n",
    "rr = Ridge(alpha = 0.001, max_iter = 100000)\n",
    "rr.fit(X_train, y_train)\n",
    "y_pred = rr.predict(X_test)\n",
    "rr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients: 795.6521694306358\n",
      "Number of coefficients not equal to 0: 104\n",
      "The R2 score is: 0.8701706652191431\n"
     ]
    }
   ],
   "source": [
    "print('Sum of coefficients:',abs(rr.coef_).sum())\n",
    "print('Number of coefficients not equal to 0:',(rr.coef_!=0).sum())\n",
    "print('The R2 score is:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,   0.   , -16.945,   2.562,   0.   ,  13.392,   9.907,\n",
       "       -19.96 ,   9.039,   0.   ,   6.138,  17.628,  11.446,   1.21 ,\n",
       "         0.226,  11.578,   2.197,  -7.397,   4.117,  -1.589,  -2.157,\n",
       "        -9.837,   0.   ,   0.   ,  -1.089,   3.793,   0.389,   0.2  ,\n",
       "        -0.297,  -3.352,   0.396,   0.719,  -0.756,  -0.753,   2.388,\n",
       "        -0.845,   2.524,  -0.973,   3.882,  -0.983,   6.609,   6.138,\n",
       "         4.201,   0.858,   1.96 ,   2.661,  -4.148,   2.937,  -4.556,\n",
       "         2.112,  -1.983,  -7.439,   1.607,   1.668,  -1.262,  -0.   ,\n",
       "        -0.   ,   2.622,  -0.861,   3.353,  -0.   ,  -2.451,   9.171,\n",
       "        -6.917,   0.   ,  -5.618,  -5.716,   0.521,   3.354,  -7.528,\n",
       "        -0.   ,  -6.646, -10.212,  -6.346,  -2.95 ,  -9.559,   0.327,\n",
       "         0.56 ,  11.006,  -6.666,  -1.158,  -2.25 ,  -3.53 ,   9.035,\n",
       "        -0.   ,  -2.316,  -2.   ,  -1.124,   0.804, -20.861,  27.166,\n",
       "         0.   ,  -1.51 ,  -6.745,  -5.098,  15.455,   0.   ,   0.   ,\n",
       "         0.629,  -3.959,   2.502,  -2.499,  -2.23 ,   2.201])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We observe that LASSO with alpha 0.001 has more zeros than Ridge with alpha 0.001\n",
    "# This is becuase, by default, LASSO will always zero more values than Ridge will.\n",
    "\n",
    "lasso3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients: 436.26164263064214\n",
      "Number of coefficients not equal to 0: 89\n",
      "The R2 score is: 0.8848141421367259\n"
     ]
    }
   ],
   "source": [
    "print('Sum of coefficients:',abs(lasso3.coef_).sum())\n",
    "print('Number of coefficients not equal to 0:',(lasso3.coef_!=0).sum())\n",
    "print('The R2 score is:', 0.8848141421367259) # LASSO has done a better generalising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Ridge does not make any coefficients 0. In addition, on this particular dataset, Lasso provides stronger overall regularization than Ridge for this value of alpha (not necessarily true in general)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
